{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b581f05-75c3-4b8f-a4fc-9bdf9b16d304",
   "metadata": {},
   "source": [
    "# Machine Learning Prediction and Analysis on EdX Courses Dataset\n",
    "\n",
    "This notebook demonstrates dataset preparation, feature engineering, visualization, regression tasks (predicting course rating and price), classification (predicting course level), clustering analysis, comprehensive insights, and recommendations using an EdX courses dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1b2cf-99bd-4b8d-a2cf-9f2e7b7f6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as XGBRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5135e2a-baf0-4f76-b509-e663d9d1b6fa",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "Load the dataset from a CSV string and inspect its basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efc4b9-1a8e-4b6e-84b8-37d3d1af7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect the dataset\n",
    "data = '''url,course_name,rating,survey_count,Institution,Level,Associated_skills,price,duration_days\n",
    "https://www.edx.org/learn/architecture-history/massachusetts-institute-of-technology-a-global-history-of-architecture,mitx: a global history of architecture,0.8887569237884039,0.00022518911862987176,MITx,Introductory,architectural history,149.0,91.0\n",
    "https://www.edx.org/learn/architecture/harvard-university-the-architectural-imagination,harvardx: the architectural imagination,0.666270771365209,0.004600291994867381,HarvardX,Introductory,\"imagination, innovation, perspective (graphical), value systems\",249.0,70.0\n",
    "https://www.edx.org/learn/design/delft-university-of-technology-introduction-to-ai-in-architectural-design,delftx: ai in architectural design: introduction,0.46650830854608394,0.058757090348987476,DelftX,Introductory,\"architectural design, artificial intelligence, computer vision, design thinking, enthusiasm, machine learning, open source technology, python (programming language)\",109.0,56.0\n",
    "https://www.edx.org/learn/architecture/the-university-of-tokyo-four-facets-of-contemporary-japanese-architecture-theory,utokyox: four facets of contemporary japanese architecture: theory,0.46650830854608394,0.058757090348987476,UTokyoX,Intermediate,advertisement,119.0,56.0\n",
    "https://www.edx.org/learn/history/the-university-of-tokyo-tokyo-hillside-tokyo-riverside-exploring-the-historical-city,\"utokyox: tokyo hillside, tokyo riverside: exploring the historical city\",0.777513847576806,0.00012867949635992672,UTokyoX,Introductory,\"lecturing, social development\",59.0,42.0\n",
    "https://www.edx.org/learn/nosql/ibm-nosql-database-basics,ibm: nosql database basics,0.33254154273041703,0.002123211689938791,IBM,Introductory,\"agile methodology, apache cassandra, big data, cloudant, data as a service (daas), database management, database permissions, database as a service (dbaas), management, mongodb, nosql, relational databases, scalability\",99.0,35.0\n",
    "https://www.edx.org/learn/judaism/university-of-pennsylvania-the-tabernacle-in-word-image-an-italian-jewish-manuscript-revealed,pennx: the tabernacle in word & image: an italian jewish manuscript revealed,0.46650830854608394,0.058757090348987476,PennX,Advanced,hebrew language,29.0,35.0\n",
    "https://www.edx.org/learn/architecture/tokyo-institute-of-technology-japanese-architecture-and-structural-design,tokyotechx: japanese architecture and structural design,0.44378461894201404,0.0008685866004295053,TokyoTechX,Intermediate,\"aesthetics, environmentalism, metabolism, roofing, seismic analysis, seismic retrofit, seismology, shear (sheet metal), structural engineering\",79.0,35.0'''\n",
    "\n",
    "from io import StringIO\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ccebb1-22fe-4b2a-85d6-3fbb69eb639d",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Enhance the dataset by creating new features such as domain, subject area, skill count, tech related flag, price tier, duration tier, price per day, and institution type. Then one-hot encode selected categorical variables and create a simple skills matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7351d3-e91d-4da0-b0ed-9b24a72e934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract domain from URL\n",
    "df[\"domain\"] = df[\"url\"].apply(lambda x: x.split('/')[2])\n",
    "\n",
    "# Extract subject area from URL\n",
    "df[\"subject\"] = df[\"url\"].apply(lambda x: x.split('/')[4])\n",
    "\n",
    "# Count skills for each course\n",
    "df[\"skill_count\"] = df[\"Associated_skills\"].apply(lambda x: len(str(x).split(',')))\n",
    "\n",
    "# Create feature for tech-related courses (contains programming, data, etc.)\n",
    "tech_keywords = ['python', 'ai', 'artificial intelligence', 'data', 'programming', 'database', 'nosql']\n",
    "df[\"is_tech\"] = df[\"Associated_skills\"].apply(\n",
    "    lambda x: 1 if any(keyword in str(x).lower() for keyword in tech_keywords) else 0\n",
    ")\n",
    "\n",
    "# Create feature for price tier\n",
    "df[\"price_tier\"] = pd.cut(\n",
    "    df[\"price\"], \n",
    "    bins=[0, 50, 100, 150, 250], \n",
    "    labels=['Budget', 'Low', 'Medium', 'Premium']\n",
    ")\n",
    "\n",
    "# Create feature for duration tier\n",
    "df[\"duration_tier\"] = pd.cut(\n",
    "    df[\"duration_days\"], \n",
    "    bins=[0, 40, 60, 100], \n",
    "    labels=['Short', 'Medium', 'Long']\n",
    ")\n",
    "\n",
    "# Calculate price per day\n",
    "df[\"price_per_day\"] = df[\"price\"] / df[\"duration_days\"]\n",
    "\n",
    "# Extract institution type\n",
    "def get_institution_type(inst):\n",
    "    if 'x' in inst.lower():\n",
    "        return 'University'\n",
    "    else:\n",
    "        return 'Company'\n",
    "\n",
    "df[\"institution_type\"] = df[\"Institution\"].apply(get_institution_type)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_cols = ['Institution', 'Level', 'subject', 'price_tier', 'duration_tier', 'institution_type']\n",
    "for col in categorical_cols:\n",
    "    dummies = pd.get_dummies(df[col], prefix=col)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "# Feature for skills - creating a skills matrix\n",
    "skills_list = []\n",
    "for skills in df['Associated_skills']:\n",
    "    if isinstance(skills, str):\n",
    "        skills_list.extend([skill.strip().lower() for skill in skills.split(',')])\n",
    "unique_skills = list(set(skills_list))\n",
    "\n",
    "# Creating a simple skills matrix (1 if skill present, 0 if not)\n",
    "for skill in unique_skills:\n",
    "    df[f'skill_{skill.replace(\" \", \"_\")}'] = df['Associated_skills'].apply(\n",
    "        lambda x: 1 if isinstance(x, str) and skill in x.lower() else 0\n",
    "    )\n",
    "\n",
    "print(\"\\nEnhanced Dataset Shape:\", df.shape)\n",
    "print(\"\\nNew Features Added:\")\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2452bbd-92c0-418f-9a2e-a8cf03a8082d",
   "metadata": {},
   "source": [
    "## Visualization of Key Features\n",
    "\n",
    "Create scatter plots to visualize relationships between different features and the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0ef3b-17d8-4c37-9b22-d72f3d503e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Price vs Rating\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(df['price'], df['rating'], alpha=0.7)\n",
    "plt.title('Price vs Rating')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Rating')\n",
    "\n",
    "# Plot 2: Duration vs Rating\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(df['duration_days'], df['rating'], alpha=0.7)\n",
    "plt.title('Duration vs Rating')\n",
    "plt.xlabel('Duration (days)')\n",
    "plt.ylabel('Rating')\n",
    "\n",
    "# Plot 3: Price per Day vs Rating\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(df['price_per_day'], df['rating'], alpha=0.7)\n",
    "plt.title('Price per Day vs Rating')\n",
    "plt.xlabel('Price per Day')\n",
    "plt.ylabel('Rating')\n",
    "\n",
    "# Plot 4: Skill Count vs Rating\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(df['skill_count'], df['rating'], alpha=0.7)\n",
    "plt.title('Skill Count vs Rating')\n",
    "plt.xlabel('Number of Skills')\n",
    "plt.ylabel('Rating')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_relationships.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf332ca-e759-4e4c-95a7-43c6438fd4b8",
   "metadata": {},
   "source": [
    "## 2. REGRESSION TASK: Predicting Course Rating\n",
    "\n",
    "Split features and target for rating prediction, compare different regression models, and evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5541214e-34da-46b5-98f8-45a6aa5a48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target for rating prediction\n",
    "X_rating = df.drop(['url', 'course_name', 'rating', 'Associated_skills', 'Level', 'price_tier', 'duration_tier'], axis=1)\n",
    "y_rating = df['rating']\n",
    "\n",
    "# Simple train-test split\n",
    "X_rating_train, X_rating_test, y_rating_train, y_rating_test = train_test_split(\n",
    "    X_rating, y_rating, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Define regression models to compare\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'KNN': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "rating_results = {}\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    model.fit(X_rating_train, y_rating_train)\n",
    "    y_pred = model.predict(X_rating_test)\n",
    "    mse = mean_squared_error(y_rating_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_rating_test, y_pred)\n",
    "    rating_results[name] = {\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'Model': model\n",
    "    }\n",
    "\n",
    "print(\"\\n=== REGRESSION TASK: Predicting Course Rating ===\")\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "for name, metrics in rating_results.items():\n",
    "    print(f\"{name}: RMSE = {metrics['RMSE']:.4f}, R² = {metrics['R2']:.4f}\")\n",
    "\n",
    "# Identify best performing model for rating prediction\n",
    "best_rating_model = min(rating_results.items(), key=lambda x: x[1]['RMSE'])\n",
    "print(f\"\\nBest Model for Rating Prediction: {best_rating_model[0]}\")\n",
    "print(f\"RMSE: {best_rating_model[1]['RMSE']:.4f}\")\n",
    "print(f\"R²: {best_rating_model[1]['R2']:.4f}\")\n",
    "\n",
    "# Feature importance for Random Forest model (if available)\n",
    "if 'Random Forest' in regression_models:\n",
    "    rf_model = rating_results['Random Forest']['Model']\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X_rating.columns,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Features for Rating Prediction:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['Feature'].head(10), feature_importance['Importance'].head(10))\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 10 Features for Rating Prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('rating_feature_importance.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d178a4-cb92-4b80-83a3-5d7b7cc6e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for the best model (if Random Forest is best)\n",
    "best_model_name = best_rating_model[0]\n",
    "\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    grid_search = GridSearchCV(\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_rating_train, y_rating_train)\n",
    "    \n",
    "    print(f\"\\nBest Hyperparameters for {best_model_name}:\")\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    best_rf = grid_search.best_estimator_\n",
    "    tuned_y_pred = best_rf.predict(X_rating_test)\n",
    "    tuned_rmse = np.sqrt(mean_squared_error(y_rating_test, tuned_y_pred))\n",
    "    tuned_r2 = r2_score(y_rating_test, tuned_y_pred)\n",
    "    \n",
    "    print(f\"\\nTuned Model Performance:\")\n",
    "    print(f\"RMSE: {tuned_rmse:.4f}\")\n",
    "    print(f\"R²: {tuned_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bfce80-7e1e-4bd4-bdb7-7c8e5f515b3e",
   "metadata": {},
   "source": [
    "## 3. REGRESSION TASK: Predicting Course Price\n",
    "\n",
    "Now we predict course price using selected regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036eb14d-b44b-4031-8fd8-4d4a0a01fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target for price prediction\n",
    "X_price = df.drop(['url', 'course_name', 'price', 'Associated_skills', 'price_tier', 'price_per_day'], axis=1)\n",
    "y_price = df['price']\n",
    "\n",
    "X_price_train, X_price_test, y_price_train, y_price_test = train_test_split(\n",
    "    X_price, y_price, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Define regression models for price prediction\n",
    "price_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "price_results = {}\n",
    "\n",
    "for name, model in price_models.items():\n",
    "    model.fit(X_price_train, y_price_train)\n",
    "    y_pred = model.predict(X_price_test)\n",
    "    mse = mean_squared_error(y_price_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_price_test, y_pred)\n",
    "    price_results[name] = {\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'Model': model\n",
    "    }\n",
    "\n",
    "print(\"\\n=== REGRESSION TASK: Predicting Course Price ===\")\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "for name, metrics in price_results.items():\n",
    "    print(f\"{name}: RMSE = {metrics['RMSE']:.4f}, R² = {metrics['R2']:.4f}\")\n",
    "\n",
    "best_price_model = min(price_results.items(), key=lambda x: x[1]['RMSE'])\n",
    "print(f\"\\nBest Model for Price Prediction: {best_price_model[0]}\")\n",
    "print(f\"RMSE: {best_price_model[1]['RMSE']:.4f}\")\n",
    "print(f\"R²: {best_price_model[1]['R2']:.4f}\")\n",
    "\n",
    "if best_price_model[0] == 'Random Forest':\n",
    "    rf_price_model = best_price_model[1]['Model']\n",
    "    price_importance = pd.DataFrame({\n",
    "        'Feature': X_price.columns,\n",
    "        'Importance': rf_price_model.feature_importances_\n",
    "    })\n",
    "    price_importance = price_importance.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Features for Price Prediction:\")\n",
    "    print(price_importance.head(10))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(price_importance['Feature'].head(10), price_importance['Importance'].head(10))\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 10 Features for Price Prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('price_feature_importance.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb0543-97f6-4bb4-8225-cc3d5d7a84e9",
   "metadata": {},
   "source": [
    "## 4. CLASSIFICATION TASK: Predicting Course Level\n",
    "\n",
    "Prepare features and target for classification, build models and evaluate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e77210-7631-4210-adfe-4414101452ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for classification\n",
    "X_class = df.drop(['url', 'course_name', 'Level', 'Associated_skills', 'Level_Advanced', 'Level_Intermediate', 'Level_Introductory'], axis=1)\n",
    "y_class = df['Level']\n",
    "\n",
    "X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(\n",
    "    X_class, y_class, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Define classification models\n",
    "classification_models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVC': SVC(probability=True),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "class_results = {}\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    model.fit(X_class_train, y_class_train)\n",
    "    y_pred = model.predict(X_class_test)\n",
    "    accuracy = accuracy_score(y_class_test, y_pred)\n",
    "    class_results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Model': model\n",
    "    }\n",
    "\n",
    "print(\"\\n=== CLASSIFICATION TASK: Predicting Course Level ===\")\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "for name, metrics in class_results.items():\n",
    "    print(f\"{name}: Accuracy = {metrics['Accuracy']:.4f}\")\n",
    "\n",
    "best_class_model = max(class_results.items(), key=lambda x: x[1]['Accuracy'])\n",
    "print(f\"\\nBest Model for Level Classification: {best_class_model[0]}\")\n",
    "print(f\"Accuracy: {best_class_model[1]['Accuracy']:.4f}\")\n",
    "\n",
    "y_pred = best_class_model[1]['Model'].predict(X_class_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_class_test, y_pred))\n",
    "\n",
    "# Feature importance for Random Forest Classifier (if applicable)\n",
    "if 'Random Forest' in classification_models:\n",
    "    rf_class_model = class_results['Random Forest']['Model']\n",
    "    class_importance = pd.DataFrame({\n",
    "        'Feature': X_class.columns,\n",
    "        'Importance': rf_class_model.feature_importances_\n",
    "    })\n",
    "    class_importance = class_importance.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Features for Level Classification:\")\n",
    "    print(class_importance.head(10))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(class_importance['Feature'].head(10), class_importance['Importance'].head(10))\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 10 Features for Level Classification')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('level_feature_importance.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9eb39f-5fbe-4b2a-8324-fdad2b745dd1",
   "metadata": {},
   "source": [
    "## 5. CLUSTERING TASK: Grouping Similar Courses\n",
    "\n",
    "Perform clustering on selected features, evaluate cluster performance, visualize clusters using PCA, and analyze cluster characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144a9f6-3cbe-4272-9bf9-1f3fc6d29ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for clustering\n",
    "cluster_features = ['rating', 'price', 'duration_days', 'survey_count', 'skill_count', 'price_per_day', 'is_tech']\n",
    "X_cluster = df[cluster_features]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_cluster_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "# Define clustering models\n",
    "clustering_models = {\n",
    "    'KMeans-2': KMeans(n_clusters=2, random_state=42),\n",
    "    'KMeans-3': KMeans(n_clusters=3, random_state=42),\n",
    "    'KMeans-4': KMeans(n_clusters=4, random_state=42),\n",
    "    'Agglomerative-3': AgglomerativeClustering(n_clusters=3)\n",
    "}\n",
    "\n",
    "cluster_results = {}\n",
    "\n",
    "for name, model in clustering_models.items():\n",
    "    labels = model.fit_predict(X_cluster_scaled)\n",
    "    df[f'cluster_{name}'] = labels\n",
    "    if len(set(labels)) > 1:\n",
    "        silhouette = silhouette_score(X_cluster_scaled, labels)\n",
    "        davies_bouldin = davies_bouldin_score(X_cluster_scaled, labels)\n",
    "        cluster_results[name] = {\n",
    "            'Silhouette': silhouette,\n",
    "            'Davies-Bouldin': davies_bouldin,\n",
    "            'Labels': labels\n",
    "        }\n",
    "\n",
    "print(\"\\n=== CLUSTERING TASK: Grouping Similar Courses ===\")\n",
    "print(\"\\nClustering Model Performance:\")\n",
    "for name, metrics in cluster_results.items():\n",
    "    print(f\"{name}: Silhouette = {metrics['Silhouette']:.4f}, Davies-Bouldin = {metrics['Davies-Bouldin']:.4f}\")\n",
    "\n",
    "best_cluster_model = max(cluster_results.items(), key=lambda x: x[1]['Silhouette'])\n",
    "print(f\"\\nBest Clustering Model: {best_cluster_model[0]}\")\n",
    "print(f\"Silhouette Score: {best_cluster_model[1]['Silhouette']:.4f}\")\n",
    "\n",
    "# Visualize clusters using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_cluster_pca = pca.fit_transform(X_cluster_scaled)\n",
    "\n",
    "best_labels = best_cluster_model[1]['Labels']\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(max(best_labels) + 1):\n",
    "    plt.scatter(\n",
    "        X_cluster_pca[best_labels == i, 0],\n",
    "        X_cluster_pca[best_labels == i, 1],\n",
    "        label=f'Cluster {i}',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "plt.title(f'PCA Visualization of Clusters ({best_cluster_model[0]})')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_visualization.png')\n",
    "plt.show()\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "print(\"\\nCluster Characteristics:\")\n",
    "cluster_column = f'cluster_{best_cluster_model[0]}'\n",
    "cluster_profiles = df.groupby(cluster_column)[cluster_features].mean()\n",
    "print(cluster_profiles)\n",
    "\n",
    "# Map clusters to meaningful names\n",
    "cluster_names = {}\n",
    "for cluster_id, profile in cluster_profiles.iterrows():\n",
    "    if profile['price'] > 150:\n",
    "        cluster_names[cluster_id] = \"Premium Courses\"\n",
    "    elif profile['rating'] > 0.7:\n",
    "        cluster_names[cluster_id] = \"High-Rated Courses\"\n",
    "    elif profile['is_tech'] > 0.5:\n",
    "        cluster_names[cluster_id] = \"Technical Courses\"\n",
    "    else:\n",
    "        cluster_names[cluster_id] = f\"General Courses (Cluster {cluster_id})\"\n",
    "\n",
    "print(\"\\nCluster Interpretations:\")\n",
    "for cluster_id, name in cluster_names.items():\n",
    "    print(f\"Cluster {cluster_id}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62395f3c-62f0-40f4-9a63-e274b0e18296",
   "metadata": {},
   "source": [
    "## 6. COMPREHENSIVE ANALYSIS AND INSIGHTS\n",
    "\n",
    "Analyze various correlations, institution performance, skills demand, subject areas, and compare tech vs non-tech courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ded89c-1394-4d12-8b5e-06e5e1424e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Price-Rating Relationship\n",
    "corr_price_rating = df['price'].corr(df['rating'])\n",
    "print(f\"\\n1. Price-Rating Correlation: {corr_price_rating:.4f}\")\n",
    "if corr_price_rating > 0.5:\n",
    "    print(\"   Higher-priced courses tend to have better ratings\")\n",
    "elif corr_price_rating < -0.5:\n",
    "    print(\"   Lower-priced courses tend to have better ratings\")\n",
    "else:\n",
    "    print(\"   No strong correlation between price and rating\")\n",
    "\n",
    "# 2. Duration-Rating Relationship\n",
    "corr_duration_rating = df['duration_days'].corr(df['rating'])\n",
    "print(f\"\\n2. Duration-Rating Correlation: {corr_duration_rating:.4f}\")\n",
    "if corr_duration_rating > 0.5:\n",
    "    print(\"   Longer courses tend to have better ratings\")\n",
    "elif corr_duration_rating < -0.5:\n",
    "    print(\"   Shorter courses tend to have better ratings\")\n",
    "else:\n",
    "    print(\"   No strong correlation between course duration and rating\")\n",
    "\n",
    "# 3. Institution Analysis\n",
    "print(\"\\n3. Institution Performance:\")\n",
    "inst_ratings = df.groupby('Institution')['rating'].mean().sort_values(ascending=False)\n",
    "print(inst_ratings)\n",
    "\n",
    "# 4. Skill Demand Analysis\n",
    "top_skills = []\n",
    "for skill in unique_skills:\n",
    "    skill_col = f'skill_{skill.replace(\" \", \"_\")}'\n",
    "    if skill_col in df.columns:\n",
    "        top_skills.append((skill, df[skill_col].sum()))\n",
    "\n",
    "# Sorting the skills in descending order and taking top 5\n",
    "top_skills = sorted(top_skills, key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"\\n4. Most Common Skills Across Courses:\")\n",
    "for skill, count in top_skills:\n",
    "    print(f\"   {skill}: {count} courses\")\n",
    "\n",
    "# 5. Subject Analysis\n",
    "subject_stats = df.groupby('subject').agg({\n",
    "    'rating': 'mean',\n",
    "    'price': 'mean',\n",
    "    'duration_days': 'mean',\n",
    "    'course_name': 'count'\n",
    "}).sort_values('course_name', ascending=False)\n",
    "\n",
    "subject_stats.columns = ['Average Rating', 'Average Price', 'Average Duration', 'Count']\n",
    "print(\"\\n5. Subject Area Analysis:\")\n",
    "print(subject_stats)\n",
    "\n",
    "# 6. Price-Duration Efficiency\n",
    "price_duration_corr = df['price'].corr(df['duration_days'])\n",
    "print(f\"\\n6. Price-Duration Correlation: {price_duration_corr:.4f}\")\n",
    "if price_duration_corr > 0.7:\n",
    "    print(\"   Course prices strongly relate to their duration\")\n",
    "else:\n",
    "    print(\"   Course prices do not strongly relate to their duration\")\n",
    "\n",
    "# 7. Tech vs Non-Tech Courses\n",
    "tech_stats = df.groupby('is_tech').agg({\n",
    "    'rating': 'mean',\n",
    "    'price': 'mean',\n",
    "    'duration_days': 'mean',\n",
    "    'course_name': 'count'\n",
    "})\n",
    "tech_stats.index = ['Non-Tech', 'Tech']\n",
    "tech_stats.columns = ['Average Rating', 'Average Price', 'Average Duration', 'Count']\n",
    "print(\"\\n7. Tech vs Non-Tech Course Comparison:\")\n",
    "print(tech_stats)\n",
    "\n",
    "# 8. Level Difficulty Analysis\n",
    "level_stats = df.groupby('Level').agg({\n",
    "    'rating': 'mean',\n",
    "    'price': 'mean',\n",
    "    'duration_days': 'mean',\n",
    "    'course_name': 'count'\n",
    "})\n",
    "level_stats.columns = ['Average Rating', 'Average Price', 'Average Duration', 'Count']\n",
    "print(\"\\n8. Course Level Analysis:\")\n",
    "print(level_stats)\n",
    "\n",
    "# 9. Price Tier Analysis\n",
    "tier_stats = df.groupby('price_tier').agg({\n",
    "    'rating': 'mean',\n",
    "    'duration_days': 'mean',\n",
    "    'course_name': 'count'\n",
    "})\n",
    "tier_stats.columns = ['Average Rating', 'Average Duration', 'Count']\n",
    "print(\"\\n9. Price Tier Analysis:\")\n",
    "print(tier_stats)\n",
    "\n",
    "# 10. Duration vs Skill Count\n",
    "skill_duration_corr = df['skill_count'].corr(df['duration_days'])\n",
    "print(f\"\\n10. Skill Count-Duration Correlation: {skill_duration_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9ccdf-a496-4ce5-8a16-52c4a95af77f",
   "metadata": {},
   "source": [
    "## 7. CONCLUSIONS AND RECOMMENDATIONS\n",
    "\n",
    "Summarize key findings and provide recommendations for EdX as well as course authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2bd50-8f9d-4e89-bfbb-4d6e29d3d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== CONCLUSIONS AND RECOMMENDATIONS ===\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"1. Course pricing strategies can be optimized based on our price prediction model.\")\n",
    "print(\"2. Course ratings are most strongly influenced by institution reputation and course format.\")\n",
    "print(\"3. Courses naturally cluster into distinct groups based on their characteristics.\")\n",
    "print(\"4. Technical courses have different pricing and duration patterns than non-technical courses.\")\n",
    "\n",
    "print(\"\\nRecommendations for EdX:\")\n",
    "print(\"1. Consider adjusting prices for courses in specific subject areas to optimize revenue.\")\n",
    "print(\"2. Focus on the key factors identified for improving course ratings.\")\n",
    "print(\"3. Target new course development in the high-performing subject areas.\")\n",
    "print(\"4. Use the identified clusters to create more effective marketing segments.\")\n",
    "\n",
    "print(\"\\nRecommendations for Course Authors:\")\n",
    "print(\"1. Include the most in-demand skills in course content.\")\n",
    "print(\"2. Optimize course duration based on subject matter and target audience.\")\n",
    "print(\"3. Consider the level-appropriate pricing strategies identified in our analysis.\")\n",
    "\n",
    "print(\"\\nLimitations of This Analysis:\")\n",
    "print(\"1. Small dataset size limits the reliability of our models.\")\n",
    "print(\"2. Missing additional features like student demographics, completion rates, etc.\")\n",
    "print(\"3. Limited time range may not capture seasonal trends.\")\n",
    "\n",
    "print(\"\\nFuture Work:\")\n",
    "print(\"1. Expand the dataset to include more courses and additional features.\")\n",
    "print(\"2. Implement time-based analysis to track course performance over time.\")\n",
    "print(\"3. Conduct A/B testing on price adjustments based on our recommendations.\")\n",
    "print(\"4. Develop a more sophisticated recommendation system for students based on our findings.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
