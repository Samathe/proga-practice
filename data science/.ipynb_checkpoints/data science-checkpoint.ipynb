{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41f30d2-fd00-494c-b02f-9127dfde405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from dateutil import parser as date_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec2eec-b058-4ef9-a285-c1e10e03d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_urls = []\n",
    "num_pages = 400  # Количество страниц\n",
    "expected_links_count = 100  # Ожидаемое количество <a> тегов (по 2 на аниме, 50 аниме)\n",
    "max_attempts = 3  # Максимальное число попыток, если найдено меньше ожидаемого количества ссылок\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' +\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) ' +\n",
    "                  'Chrome/90.0.4430.93 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'ru-RU,ru;q=0.9'\n",
    "})\n",
    "\n",
    "for page in range(num_pages):\n",
    "    limit = page * 50\n",
    "    list_page_url = f\"https://myanimelist.net/topanime.php?limit={limit}\"\n",
    "    attempt = 0\n",
    "    links = []\n",
    "    \n",
    "    # Если найдено меньше ожидаемого количества ссылок, пробуем ещё раз с увеличенной задержкой\n",
    "    while attempt < max_attempts:\n",
    "        response = session.get(list_page_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        links = soup.find_all(\"a\", class_=\"hoverinfo_trigger\")\n",
    "        \n",
    "        if len(links) < expected_links_count:\n",
    "            print(f\"Страница {page+1}: найдено только {len(links)} ссылок. Ожидание для повторной загрузки...\")\n",
    "            time.sleep(3 + random.uniform(0, 2))\n",
    "            attempt += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if len(links) < expected_links_count:\n",
    "        print(f\"Страница {page+1}: недостаточное количество ссылок, продолжаем дальше.\")\n",
    "    \n",
    "    # Берём каждую вторую ссылку (индексы 1, 3, 5, ...) чтобы избежать дублей\n",
    "    for i in range(1, len(links), 2):\n",
    "        url = links[i].get(\"href\")\n",
    "        anime_urls.append(url)\n",
    "    \n",
    "    time.sleep(1 + random.uniform(0, 1))\n",
    "\n",
    "# Сохраняем все ссылки в файл \"anime_urls.txt\" (каждая ссылка с новой строки)\n",
    "with open(\"anime_urls2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for url in anime_urls:\n",
    "        f.write(url + \"\\n\")\n",
    "\n",
    "print(\"Общее количество собранных ссылок:\", len(anime_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c916b7b-f493-42be-942b-aa0e99f46b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Чтение файла и сохранение ссылок в список\n",
    "with open(\"anime_urls.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    anime_links = [line.strip() for line in file if line.strip()]\n",
    "len(anime_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3143c2-84d1-4aa7-b5c2-46b7c0775228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dateutil import parser as date_parser\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_fields(text):\n",
    "    fields = {}\n",
    "    \n",
    "    # 1. Anime Type\n",
    "    m_type = re.search(r\"Type:\\s*([^\\n]+)\", text)\n",
    "    fields[\"animeType\"] = m_type.group(1).strip() if m_type else None\n",
    "    \n",
    "    # 2. Number of episodes\n",
    "    m_episodes = re.search(r\"Episodes:\\s*(\\d+)\", text)\n",
    "    fields[\"animeNumEpisode\"] = int(m_episodes.group(1)) if m_episodes else None\n",
    "    \n",
    "    # 3. Aired: извлекаем строку и парсим даты\n",
    "    m_aired = re.search(r\"Aired:\\s*([^\\n]+)\", text)\n",
    "    if m_aired:\n",
    "        aired_str = m_aired.group(1).strip()\n",
    "        if \" to \" in aired_str:\n",
    "            release_str, end_str = aired_str.split(\" to \", 1)\n",
    "            try:\n",
    "                fields[\"releaseDate\"] = date_parser.parse(release_str.strip(), fuzzy=True)\n",
    "            except Exception:\n",
    "                fields[\"releaseDate\"] = None\n",
    "            try:\n",
    "                fields[\"endDate\"] = date_parser.parse(end_str.strip(), fuzzy=True)\n",
    "            except Exception:\n",
    "                fields[\"endDate\"] = None\n",
    "        else:\n",
    "            try:\n",
    "                fields[\"releaseDate\"] = date_parser.parse(aired_str.strip(), fuzzy=True)\n",
    "            except Exception:\n",
    "                fields[\"releaseDate\"] = None\n",
    "            fields[\"endDate\"] = None\n",
    "    else:\n",
    "        fields[\"Aired\"] = None\n",
    "        fields[\"releaseDate\"] = None\n",
    "        fields[\"endDate\"] = None\n",
    "\n",
    "    # 4. Score\n",
    "    m_score = re.search(r\"Score:\\s*([\\d\\.]+)\", text)\n",
    "    fields[\"animeScore\"] = float(m_score.group(1)) if m_score else None\n",
    "    \n",
    "    # 5. Users (число пользователей, оценивших аниме)\n",
    "    m_users = re.search(r\"scored by\\s*([\\d,]+)\", text)\n",
    "    if m_users:\n",
    "        try:\n",
    "            fields[\"animeUsers\"] = int(m_users.group(1).replace(\",\", \"\"))\n",
    "        except Exception:\n",
    "            fields[\"animeUsers\"] = None\n",
    "    else:\n",
    "        fields[\"animeUsers\"] = None\n",
    "        \n",
    "    # 6. Rank\n",
    "    m_rank = re.search(r\"Ranked:\\s*#(\\d+)\", text)\n",
    "    fields[\"animeRank\"] = int(m_rank.group(1)) if m_rank else None\n",
    "    \n",
    "    # 7. Popularity\n",
    "    m_pop = re.search(r\"Popularity:\\s*#(\\d+)\", text)\n",
    "    fields[\"animePopularity\"] = int(m_pop.group(1)) if m_pop else None\n",
    "    \n",
    "    # 8. Number of members\n",
    "    m_members = re.search(r\"Members:\\s*([\\d,]+)\", text)\n",
    "    if m_members:\n",
    "        try:\n",
    "            fields[\"animeNumMembers\"] = int(m_members.group(1).replace(\",\", \"\"))\n",
    "        except Exception:\n",
    "            fields[\"animeNumMembers\"] = None\n",
    "    else:\n",
    "        fields[\"animeNumMembers\"] = None\n",
    "\n",
    "    # Создаем временный объект BeautifulSoup для поиска по DOM\n",
    "    temp_soup = BeautifulSoup(text, \"html.parser\")\n",
    "    \n",
    "    # 9. Synopsis (animeDescription): извлекаем текст из <p itemprop=\"description\">\n",
    "    synopsis_tag = temp_soup.find_all(\"p\")\n",
    "    fields[\"animeDescription\"] = synopsis_tag.get_text(strip=True) if synopsis_tag else None\n",
    "    \n",
    "    # 10. Related Anime (animeRelated): ищем все <a> внутри <td class=\"pb24\"> и оставляем уникальные значения\n",
    "    related_td = temp_soup.find(\"td\", class_=\"pb24\")\n",
    "    related_set = set()\n",
    "    if related_td:\n",
    "        for a in related_td.find_all(\"a\", href=True):\n",
    "            a_text = a.get_text(strip=True)\n",
    "            if a_text:\n",
    "                related_set.add(a_text)\n",
    "    fields[\"animeRelated\"] = list(related_set)\n",
    "    \n",
    "    # 11. Characters и 12. Voices:\n",
    "    # Извлекаем все <td class=\"borderClass\">. Нечётные элементы – Characters, чётные – Voices.\n",
    "    tds = temp_soup.find_all(\"div\", class_=\"detail-characters-list clearfix\")\n",
    "    animeCharacters = []\n",
    "    animeVoices = []\n",
    "    for i, td in enumerate(tds):\n",
    "        if i % 2 == 0:\n",
    "            animeCharacters.append(td.get_text(strip=True))\n",
    "        else:\n",
    "            animeVoices.append(td.get_text(strip=True))\n",
    "    fields[\"animeCharacters\"] = animeCharacters\n",
    "    fields[\"animeVoices\"] = animeVoices\n",
    "\n",
    "    # 13. Staff (animeStaff): извлекаем информацию о персонале (имя и роль)\n",
    "    animeStaff = []\n",
    "    staff_container = temp_soup.find(\"div\", class_=\"staff-section\")\n",
    "    if staff_container:\n",
    "        for row in staff_container.find_all(\"tr\"):\n",
    "            cols = row.find_all(\"td\")\n",
    "            if len(cols) >= 2:\n",
    "                name = cols[0].get_text(strip=True)\n",
    "                role = cols[1].get_text(strip=True)\n",
    "                animeStaff.append([name, role])\n",
    "    fields[\"animeStaff\"] = animeStaff\n",
    "    \n",
    "    return fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de0ac02-4998-422d-88ec-5e68ed3d1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_additional_fields(soup):\n",
    "    additional = {}\n",
    "    \n",
    "    # 9. Synopsis (animeDescription): извлекаем текст из <p itemprop=\"description\">\n",
    "    synopsis_tag = soup.find(\"p\", itemprop=\"description\")\n",
    "    additional[\"animeDescription\"] = synopsis_tag.get_text(strip=True) if synopsis_tag else None\n",
    "    \n",
    "    # 10. Related Anime (animeRelated): ищем контейнер <div class=\"related-entries\">\n",
    "    # внутри него находим все <div class=\"title\"> и извлекаем текст и href из вложенного <a>\n",
    "    related_div = soup.find(\"div\", class_=\"related-entries\")\n",
    "    related_dict = {}\n",
    "    if related_div:\n",
    "        title_divs = related_div.find_all(\"div\", class_=\"title\")\n",
    "        for div in title_divs:\n",
    "            a_tag = div.find(\"a\", href=True)\n",
    "            if a_tag:\n",
    "                title_text = a_tag.get_text(strip=True)\n",
    "                href = a_tag.get(\"href\")\n",
    "                if title_text and href and title_text not in related_dict:\n",
    "                    related_dict[title_text] = href\n",
    "    additional[\"animeRelated\"] = [{\"title\": title, \"href\": href} for title, href in related_dict.items()]\n",
    "    \n",
    "    # 11. Characters: находим контейнер <div class=\"detail-characters-list clearfix\">\n",
    "    # и внутри него все <h3 class=\"h3_characters_voice_actors\">\n",
    "    animeCharacters = []\n",
    "    detail_div = soup.find(\"div\", class_=\"detail-characters-list clearfix\")\n",
    "    if detail_div:\n",
    "        h3_tags = detail_div.find_all(\"h3\", class_=\"h3_characters_voice_actors\")\n",
    "        for h3 in h3_tags:\n",
    "            text_val = h3.get_text(strip=True)\n",
    "            if text_val:\n",
    "                animeCharacters.append(text_val)\n",
    "    if animeCharacters == []:\n",
    "        animeCharacters = None\n",
    "    additional[\"animeCharacters\"] = animeCharacters\n",
    "        \n",
    "    # 12. Voices: в том же контейнере detail_div ищем все <td> с классом, содержащим \"va-t\", \"ar\", \"pl4\", \"pr4\"\n",
    "    animeVoices = []\n",
    "    if detail_div:\n",
    "        voice_tds = detail_div.find_all(\"td\", class_=lambda x: x and all(cls in x.split() for cls in [\"va-t\", \"ar\", \"pl4\", \"pr4\"]))\n",
    "        for td in voice_tds:\n",
    "            # Извлекаем текст из вложенных <a>\n",
    "            for a in td.find_all(\"a\", href=True):\n",
    "                text_val = a.get_text(strip=True)\n",
    "                if text_val:\n",
    "                    animeVoices.append(text_val)\n",
    "    if animeVoices == []:\n",
    "        animeVoices = None\n",
    "    additional[\"animeVoices\"] = animeVoices\n",
    "\n",
    "    # 13. Staff (animeStaff): теперь ищем все <a> внутри того же контейнера detail_div\n",
    "    animeStaff = []\n",
    "    if detail_div:\n",
    "        for a in detail_div.find_all(\"a\", href=True):\n",
    "            name = a.get_text(strip=True)\n",
    "            if name:\n",
    "                animeStaff.append(name)\n",
    "    if animeStaff == []:\n",
    "        animeStaff = None\n",
    "    additional[\"animeStaff\"] = animeStaff\n",
    "    \n",
    "    return additional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e6d34f-1847-43d4-b573-11e304e86415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import random\n",
    "from dateutil import parser as date_parser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Настраиваем сессию с заголовками, имитирующими браузер\n",
    "headers = {\n",
    "    \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                   \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                   \"Chrome/107.0.5304.110 Safari/537.36\")\n",
    "}\n",
    "session = requests.Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "data = []  # Список для хранения собранных данных\n",
    "\n",
    "for link in anime_links[:]:\n",
    "    try:\n",
    "        response = session.get(link)\n",
    "        if response.status_code == 200:\n",
    "            # Создаем объект BeautifulSoup для всей страницы\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            \n",
    "            # Извлекаем название аниме\n",
    "            title_tag = soup.find(\"h1\", class_=\"title-name h1_bold_none\")\n",
    "            anime_title = title_tag.get_text(strip=True) if title_tag else \"Нет названия\"\n",
    "            \n",
    "            # Для базовых характеристик используем объединенный текст из всех <div class=\"spaceit_pad\">\n",
    "            divs = soup.find_all(\"div\", class_=\"spaceit_pad\")\n",
    "            combined_text = \"\\n\".join(div.get_text(separator=\" \", strip=True) for div in divs)\n",
    "            fields = extract_fields(combined_text)\n",
    "            \n",
    "            # Извлекаем дополнительные поля с использованием DOM (soup)\n",
    "            additional = extract_additional_fields(soup)\n",
    "            \n",
    "            # Собираем итоговую запись\n",
    "            record = {\n",
    "                \"url\": link,\n",
    "                \"animeTitle\": anime_title,\n",
    "            }\n",
    "            record.update(fields)\n",
    "            record.update(additional)\n",
    "            data.append(record)\n",
    "        else:\n",
    "            print(f\"Ошибка загрузки {link} - статус код: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке {link}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4186327-cd9d-440c-b944-07ed46cb996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57834c26-08fb-44f4-9e0e-50a10fa15337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "385a64fd-f3e8-4f4d-9c88-e3353e3face4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>animeTitle</th>\n",
       "      <th>animeType</th>\n",
       "      <th>animeNumEpisode</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>endDate</th>\n",
       "      <th>animeScore</th>\n",
       "      <th>animeUsers</th>\n",
       "      <th>animeRank</th>\n",
       "      <th>animePopularity</th>\n",
       "      <th>animeNumMembers</th>\n",
       "      <th>animeDescription</th>\n",
       "      <th>animeRelated</th>\n",
       "      <th>animeCharacters</th>\n",
       "      <th>animeVoices</th>\n",
       "      <th>animeStaff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://myanimelist.net/anime/52991/Sousou_no_...</td>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>TV</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2023-09-29</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>9.31</td>\n",
       "      <td>604590.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1037287</td>\n",
       "      <td>During their decade-long quest to defeat the D...</td>\n",
       "      <td>[{'title': 'Sousou no Frieren 2nd Season', 'hr...</td>\n",
       "      <td>[Frieren, Fern, Stark, Himmel, Übel, Flamme, E...</td>\n",
       "      <td>[Tanezaki, Atsumi, Ichinose, Kana, Kobayashi, ...</td>\n",
       "      <td>[Frieren, Tanezaki, Atsumi, Fern, Ichinose, Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://myanimelist.net/anime/5114/Fullmetal_A...</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>TV</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>2010-07-04</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2196752.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3483954</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>[{'title': 'Fullmetal Alchemist', 'href': 'htt...</td>\n",
       "      <td>[Elric, Edward, Elric, Alphonse, Mustang, Roy,...</td>\n",
       "      <td>[Park, Romi, Kugimiya, Rie, Miki, Shinichiro, ...</td>\n",
       "      <td>[Elric, Edward, Park, Romi, Elric, Alphonse, K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://myanimelist.net/anime/9253/Steins_Gate</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>TV</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2011-04-06</td>\n",
       "      <td>2011-09-14</td>\n",
       "      <td>9.07</td>\n",
       "      <td>1450196.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2668679</td>\n",
       "      <td>Eccentric scientist Rintarou Okabe has a never...</td>\n",
       "      <td>[{'title': 'Steins;Gate: Oukoubakko no Porioma...</td>\n",
       "      <td>[Okabe, Rintarou, Makise, Kurisu, Shiina, Mayu...</td>\n",
       "      <td>[Miyano, Mamoru, Imai, Asami, Hanazawa, Kana, ...</td>\n",
       "      <td>[Okabe, Rintarou, Miyano, Mamoru, Makise, Kuri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://myanimelist.net/anime/60022/One_Piece_...</td>\n",
       "      <td>One Piece Fan Letter</td>\n",
       "      <td>TV Special</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>9.06</td>\n",
       "      <td>69269.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2343</td>\n",
       "      <td>91711</td>\n",
       "      <td>Although the golden age of piracy is about to ...</td>\n",
       "      <td>[{'title': 'One Piece Novel: Mugiwara Stories'...</td>\n",
       "      <td>[Girl, Marine Older Brother, Monkey D., Luffy,...</td>\n",
       "      <td>[Kikuchi, Kokoro, Kase, Yasuyuki, Tanaka, Mayu...</td>\n",
       "      <td>[Girl, Kikuchi, Kokoro, Marine Older Brother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://myanimelist.net/anime/38524/Shingeki_n...</td>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>TV</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>9.05</td>\n",
       "      <td>1671420.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2408638</td>\n",
       "      <td>Seeking to restore humanity's diminishing hope...</td>\n",
       "      <td>[{'title': 'Shingeki no Kyojin Season 3', 'hre...</td>\n",
       "      <td>[Levi, Yeager, Eren, Ackerman, Mikasa, Arlert,...</td>\n",
       "      <td>[Kamiya, Hiroshi, Kaji, Yuuki, Ishikawa, Yui, ...</td>\n",
       "      <td>[Levi, Kamiya, Hiroshi, Yeager, Eren, Kaji, Yu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>https://myanimelist.net/anime/53102/Chunkun</td>\n",
       "      <td>Chunkun</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20005</td>\n",
       "      <td>23742</td>\n",
       "      <td>116</td>\n",
       "      <td>On a spring day, the heroine falls asleep in h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>https://myanimelist.net/anime/43824/Chuntian_L...</td>\n",
       "      <td>Chuntian Li De Xiaotian Shu</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1992-03-02</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20006</td>\n",
       "      <td>24674</td>\n",
       "      <td>99</td>\n",
       "      <td>No synopsis information has been added to this...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>https://myanimelist.net/anime/54428/Chuuchuu</td>\n",
       "      <td>Chuuchuu</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20007</td>\n",
       "      <td>22685</td>\n",
       "      <td>146</td>\n",
       "      <td>A man was born. He met a woman whom he fell in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>https://myanimelist.net/anime/24927/Chuuchuu_B...</td>\n",
       "      <td>Chuuchuu Banban</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1970-03-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20008</td>\n",
       "      <td>18619</td>\n",
       "      <td>372</td>\n",
       "      <td>No synopsis information has been added to this...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Professor, Muller, Buck, Doragorou, Bun]</td>\n",
       "      <td>[Matsushima, Minori, Sakamoto, Shinpei, Ootake...</td>\n",
       "      <td>[Professor, Matsushima, Minori, Muller, Buck, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>https://myanimelist.net/anime/31690/Chuugakusei</td>\n",
       "      <td>Chuugakusei</td>\n",
       "      <td>OVA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011-05-13</td>\n",
       "      <td>2012-04-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20009</td>\n",
       "      <td>19489</td>\n",
       "      <td>313</td>\n",
       "      <td>The story takes place on a faraway planet, cal...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      https://myanimelist.net/anime/52991/Sousou_no_...   \n",
       "1      https://myanimelist.net/anime/5114/Fullmetal_A...   \n",
       "2         https://myanimelist.net/anime/9253/Steins_Gate   \n",
       "3      https://myanimelist.net/anime/60022/One_Piece_...   \n",
       "4      https://myanimelist.net/anime/38524/Shingeki_n...   \n",
       "...                                                  ...   \n",
       "19995        https://myanimelist.net/anime/53102/Chunkun   \n",
       "19996  https://myanimelist.net/anime/43824/Chuntian_L...   \n",
       "19997       https://myanimelist.net/anime/54428/Chuuchuu   \n",
       "19998  https://myanimelist.net/anime/24927/Chuuchuu_B...   \n",
       "19999    https://myanimelist.net/anime/31690/Chuugakusei   \n",
       "\n",
       "                               animeTitle   animeType  animeNumEpisode  \\\n",
       "0                       Sousou no Frieren          TV             28.0   \n",
       "1        Fullmetal Alchemist: Brotherhood          TV             64.0   \n",
       "2                             Steins;Gate          TV             24.0   \n",
       "3                    One Piece Fan Letter  TV Special              1.0   \n",
       "4      Shingeki no Kyojin Season 3 Part 2          TV             10.0   \n",
       "...                                   ...         ...              ...   \n",
       "19995                             Chunkun       Movie              1.0   \n",
       "19996         Chuntian Li De Xiaotian Shu       Movie              1.0   \n",
       "19997                            Chuuchuu       Movie              1.0   \n",
       "19998                     Chuuchuu Banban       Movie              1.0   \n",
       "19999                         Chuugakusei         OVA              2.0   \n",
       "\n",
       "      releaseDate    endDate  animeScore  animeUsers  animeRank  \\\n",
       "0      2023-09-29 2024-03-22        9.31    604590.0          1   \n",
       "1      2009-04-05 2010-07-04        9.10   2196752.0          2   \n",
       "2      2011-04-06 2011-09-14        9.07   1450196.0          3   \n",
       "3      2024-10-20        NaT        9.06     69269.0          4   \n",
       "4      2019-04-29 2019-07-01        9.05   1671420.0          5   \n",
       "...           ...        ...         ...         ...        ...   \n",
       "19995  2018-07-01        NaT         NaN         NaN      20005   \n",
       "19996  1992-03-02        NaT         NaN         NaN      20006   \n",
       "19997  2015-02-02        NaT         NaN         NaN      20007   \n",
       "19998  1970-03-17        NaT         NaN         NaN      20008   \n",
       "19999  2011-05-13 2012-04-27         NaN         NaN      20009   \n",
       "\n",
       "       animePopularity  animeNumMembers  \\\n",
       "0                  160          1037287   \n",
       "1                    3          3483954   \n",
       "2                   14          2668679   \n",
       "3                 2343            91711   \n",
       "4                   21          2408638   \n",
       "...                ...              ...   \n",
       "19995            23742              116   \n",
       "19996            24674               99   \n",
       "19997            22685              146   \n",
       "19998            18619              372   \n",
       "19999            19489              313   \n",
       "\n",
       "                                        animeDescription  \\\n",
       "0      During their decade-long quest to defeat the D...   \n",
       "1      After a horrific alchemy experiment goes wrong...   \n",
       "2      Eccentric scientist Rintarou Okabe has a never...   \n",
       "3      Although the golden age of piracy is about to ...   \n",
       "4      Seeking to restore humanity's diminishing hope...   \n",
       "...                                                  ...   \n",
       "19995  On a spring day, the heroine falls asleep in h...   \n",
       "19996  No synopsis information has been added to this...   \n",
       "19997  A man was born. He met a woman whom he fell in...   \n",
       "19998  No synopsis information has been added to this...   \n",
       "19999  The story takes place on a faraway planet, cal...   \n",
       "\n",
       "                                            animeRelated  \\\n",
       "0      [{'title': 'Sousou no Frieren 2nd Season', 'hr...   \n",
       "1      [{'title': 'Fullmetal Alchemist', 'href': 'htt...   \n",
       "2      [{'title': 'Steins;Gate: Oukoubakko no Porioma...   \n",
       "3      [{'title': 'One Piece Novel: Mugiwara Stories'...   \n",
       "4      [{'title': 'Shingeki no Kyojin Season 3', 'hre...   \n",
       "...                                                  ...   \n",
       "19995                                                 []   \n",
       "19996                                                 []   \n",
       "19997                                                 []   \n",
       "19998                                                 []   \n",
       "19999                                                 []   \n",
       "\n",
       "                                         animeCharacters  \\\n",
       "0      [Frieren, Fern, Stark, Himmel, Übel, Flamme, E...   \n",
       "1      [Elric, Edward, Elric, Alphonse, Mustang, Roy,...   \n",
       "2      [Okabe, Rintarou, Makise, Kurisu, Shiina, Mayu...   \n",
       "3      [Girl, Marine Older Brother, Monkey D., Luffy,...   \n",
       "4      [Levi, Yeager, Eren, Ackerman, Mikasa, Arlert,...   \n",
       "...                                                  ...   \n",
       "19995                                               None   \n",
       "19996                                               None   \n",
       "19997                                               None   \n",
       "19998          [Professor, Muller, Buck, Doragorou, Bun]   \n",
       "19999                                               None   \n",
       "\n",
       "                                             animeVoices  \\\n",
       "0      [Tanezaki, Atsumi, Ichinose, Kana, Kobayashi, ...   \n",
       "1      [Park, Romi, Kugimiya, Rie, Miki, Shinichiro, ...   \n",
       "2      [Miyano, Mamoru, Imai, Asami, Hanazawa, Kana, ...   \n",
       "3      [Kikuchi, Kokoro, Kase, Yasuyuki, Tanaka, Mayu...   \n",
       "4      [Kamiya, Hiroshi, Kaji, Yuuki, Ishikawa, Yui, ...   \n",
       "...                                                  ...   \n",
       "19995                                               None   \n",
       "19996                                               None   \n",
       "19997                                               None   \n",
       "19998  [Matsushima, Minori, Sakamoto, Shinpei, Ootake...   \n",
       "19999                                               None   \n",
       "\n",
       "                                              animeStaff  \n",
       "0      [Frieren, Tanezaki, Atsumi, Fern, Ichinose, Ka...  \n",
       "1      [Elric, Edward, Park, Romi, Elric, Alphonse, K...  \n",
       "2      [Okabe, Rintarou, Miyano, Mamoru, Makise, Kuri...  \n",
       "3      [Girl, Kikuchi, Kokoro, Marine Older Brother, ...  \n",
       "4      [Levi, Kamiya, Hiroshi, Yeager, Eren, Kaji, Yu...  \n",
       "...                                                  ...  \n",
       "19995                                               None  \n",
       "19996                                               None  \n",
       "19997                                               None  \n",
       "19998  [Professor, Matsushima, Minori, Muller, Buck, ...  \n",
       "19999                                               None  \n",
       "\n",
       "[20000 rows x 16 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "765a74d0-9848-4f40-ac46-af9fa5f66a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"anime.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
